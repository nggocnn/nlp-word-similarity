{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading ../word2vec/W2V_150.txt to variables: 77023it [00:07, 10568.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, List\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import string\n",
    "from scipy.spatial import distance\n",
    "\n",
    "word2vecpath = '../word2vec/W2V_150.txt'\n",
    "visim = '../Datasets/ViSim-400'\n",
    "vicon = '../Datasets/ViCon-400'\n",
    "words = []\n",
    "vecs = []\n",
    "dim = None\n",
    "n_vocab = None\n",
    "\n",
    "\n",
    "def word2norm(a: str) -> str:\n",
    "    table = str.maketrans(dict.fromkeys(\n",
    "        string.punctuation))  # OR {key: None for key in string.punctuation}\n",
    "    new_s = a.translate(table)\n",
    "    return new_s\n",
    "\n",
    "\n",
    "with open(word2vecpath, encoding='utf8') as f:\n",
    "    for line in tqdm(f, f\"loading {word2vecpath} to variables\"):\n",
    "        if not n_vocab:\n",
    "            n_vocab = int(line)\n",
    "        elif not dim:\n",
    "            dim = int(line)\n",
    "        else:\n",
    "            line = line.replace('\\n', '')\n",
    "            words.append(word2norm(line.split('  ')[0]))\n",
    "            vecs.append([float(i) for i in line.split('  ')[1].split()])\n",
    "vecs = np.array(vecs)\n",
    "\n",
    "\n",
    "def word2vec(a: str) -> np.array:\n",
    "    try:\n",
    "        a = word2norm(a)\n",
    "        i = words.index(a)\n",
    "        return vecs[i]\n",
    "    except:\n",
    "        return np.zeros(dim)\n",
    "\n",
    "\n",
    "def cosine(a: np.array, b: np.array) -> float:\n",
    "    a = a / np.linalg.norm(a) if np.linalg.norm(a) != 0 else a\n",
    "    b = b / np.linalg.norm(b) if np.linalg.norm(b) != 0 else b\n",
    "    return a.dot(b)\n",
    "\n",
    "\n",
    "#  Dot\tProduct Distance, Euclidean Distance, Dice Distance, Jaccard Distance.\n",
    "\n",
    "\n",
    "def dot(a: np.array, b: np.array) -> float:\n",
    "    return a.dot(b)\n",
    "\n",
    "\n",
    "def euclid(a: np.array, b: np.array) -> float:\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "\n",
    "def dice(a: np.array, b: np.array) -> float:\n",
    "    return distance.dice(a, b)\n",
    "\n",
    "\n",
    "def jaccard(a: np.array, b: np.array) -> float:\n",
    "    return distance.jaccard(a, b, w=None)\n",
    "\n",
    "\n",
    "def sim(row, sim_f=cosine):\n",
    "    vec1 = word2vec(row.iloc[0])\n",
    "    vec2 = word2vec(row.iloc[1])\n",
    "    return sim_f(vec1, vec2)\n",
    "\n",
    "\n",
    "def topn(w: str,\n",
    "         vocab: List[str] = words,\n",
    "         encoder: Callable = word2vec,\n",
    "         distance_by: Callable = cosine,\n",
    "         n: int = 5) -> list:\n",
    "    input_encode = encoder(w)\n",
    "    vocab_sim = [(other, distance_by(input_encode, encoder(other)))\n",
    "                 for other in tqdm(vocab, \"Scanning vocab\")]\n",
    "    vocab_sim.sort(key=lambda x: x[1], reverse=True)\n",
    "    return vocab_sim[:n] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>Relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>giải_thoát</td>\n",
       "      <td>thi_hành</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kìm_giữ</td>\n",
       "      <td>trói_buộc</td>\n",
       "      <td>SYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gây_lộn</td>\n",
       "      <td>gây_sự</td>\n",
       "      <td>SYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lầm</td>\n",
       "      <td>nhầm</td>\n",
       "      <td>SYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chuyển_dạ</td>\n",
       "      <td>trở_dạ</td>\n",
       "      <td>SYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>ấm_áp</td>\n",
       "      <td>lạnh_lẽo</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>mập</td>\n",
       "      <td>ngẳng</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>chóng</td>\n",
       "      <td>lâu</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>chậm</td>\n",
       "      <td>sớm</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>ngăn_nắp</td>\n",
       "      <td>lung_tung</td>\n",
       "      <td>ANT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word1      Word2 Relation\n",
       "0    giải_thoát   thi_hành      ANT\n",
       "1       kìm_giữ  trói_buộc      SYN\n",
       "2       gây_lộn     gây_sự      SYN\n",
       "3           lầm       nhầm      SYN\n",
       "4     chuyển_dạ     trở_dạ      SYN\n",
       "..          ...        ...      ...\n",
       "595       ấm_áp   lạnh_lẽo      ANT\n",
       "596         mập      ngẳng      ANT\n",
       "597       chóng        lâu      ANT\n",
       "598        chậm        sớm      ANT\n",
       "599    ngăn_nắp  lung_tung      ANT\n",
       "\n",
       "[1400 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "\n",
    "simpairs = pd.read_csv(visim + '/Visim-400.txt', sep=\"\\t\")\n",
    "npairs = pd.read_csv(vicon + '/400_verb_pairs.txt', sep=\"\\t\")\n",
    "vpairs = pd.read_csv(vicon + '/400_verb_pairs.txt', sep=\"\\t\")\n",
    "apairs = pd.read_csv(vicon + '/600_adj_pairs.txt', sep=\"\\t\")\n",
    "dataset =  pd.concat([npairs, vpairs, apairs])[['Word1',\t'Word2',\t'Relation']]\n",
    "\n",
    "def flatten(row):\n",
    "    vec1 = word2vec(row.iloc[0])\n",
    "    vec2 = word2vec(row.iloc[1])\n",
    "    return np.array([vec1, vec2])\n",
    "\n",
    "X = np.array([i for i in dataset.apply(flatten, axis=1)])\n",
    "y = enc.fit_transform(dataset['Relation'].values.reshape(-1,1))\n",
    "    \n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\spatial\\distance.py:1424: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return float((ntf + nft) / np.array(2.0 * ntt + ntf + nft))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>Sim1</th>\n",
       "      <th>Sim2</th>\n",
       "      <th>STD</th>\n",
       "      <th>sim-cosine</th>\n",
       "      <th>sim-dot</th>\n",
       "      <th>sim-euclid</th>\n",
       "      <th>sim-dice</th>\n",
       "      <th>sim-jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biến</td>\n",
       "      <td>ngập</td>\n",
       "      <td>V</td>\n",
       "      <td>3.13</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.004912</td>\n",
       "      <td>-1.493676</td>\n",
       "      <td>25.296228</td>\n",
       "      <td>0.808093</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nhà_thi_đấu</td>\n",
       "      <td>nhà</td>\n",
       "      <td>N</td>\n",
       "      <td>3.07</td>\n",
       "      <td>5.12</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.082523</td>\n",
       "      <td>18.257401</td>\n",
       "      <td>22.118834</td>\n",
       "      <td>-3.074252</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>động</td>\n",
       "      <td>tĩnh</td>\n",
       "      <td>V</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.277086</td>\n",
       "      <td>39.547434</td>\n",
       "      <td>14.640360</td>\n",
       "      <td>-24.627852</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>khuyết</td>\n",
       "      <td>ưu</td>\n",
       "      <td>N</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.176799</td>\n",
       "      <td>40.841349</td>\n",
       "      <td>19.508880</td>\n",
       "      <td>-0.468402</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cõi_tục</td>\n",
       "      <td>cõi_âm</td>\n",
       "      <td>N</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.063605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>lình_xình</td>\n",
       "      <td>nặng_tình</td>\n",
       "      <td>A</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.170494</td>\n",
       "      <td>38.338900</td>\n",
       "      <td>19.600983</td>\n",
       "      <td>-1.993741</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>người_làm</td>\n",
       "      <td>người_bị_hại</td>\n",
       "      <td>N</td>\n",
       "      <td>2.20</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.135008</td>\n",
       "      <td>27.805490</td>\n",
       "      <td>18.980925</td>\n",
       "      <td>-3.418888</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>cõi_tục</td>\n",
       "      <td>trần_gian</td>\n",
       "      <td>N</td>\n",
       "      <td>5.40</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.601425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>chần_chừ</td>\n",
       "      <td>lảo_đảo</td>\n",
       "      <td>V</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.112939</td>\n",
       "      <td>20.632544</td>\n",
       "      <td>18.305506</td>\n",
       "      <td>5.200466</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>khử_trùng</td>\n",
       "      <td>sát_trùng</td>\n",
       "      <td>V</td>\n",
       "      <td>5.53</td>\n",
       "      <td>9.22</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.705227</td>\n",
       "      <td>190.563691</td>\n",
       "      <td>13.240623</td>\n",
       "      <td>9.162421</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word1         Word2 POS  Sim1  Sim2   STD  sim-cosine     sim-dot  \\\n",
       "0           biến          ngập   V  3.13  5.22  0.72   -0.004912   -1.493676   \n",
       "1    nhà_thi_đấu           nhà   N  3.07  5.12  1.18    0.082523   18.257401   \n",
       "2           động          tĩnh   V  0.60  1.00  0.95    0.277086   39.547434   \n",
       "3         khuyết            ưu   N  0.20  0.33  0.40    0.176799   40.841349   \n",
       "4        cõi_tục        cõi_âm   N  0.60  1.00  0.95    0.000000    0.000000   \n",
       "..           ...           ...  ..   ...   ...   ...         ...         ...   \n",
       "395    lình_xình     nặng_tình   A  1.33  2.22  1.14    0.170494   38.338900   \n",
       "396    người_làm  người_bị_hại   N  2.20  3.67  0.83    0.135008   27.805490   \n",
       "397      cõi_tục     trần_gian   N  5.40  9.00  0.71    0.000000    0.000000   \n",
       "398     chần_chừ       lảo_đảo   V  3.20  5.33  0.98    0.112939   20.632544   \n",
       "399    khử_trùng     sát_trùng   V  5.53  9.22  0.81    0.705227  190.563691   \n",
       "\n",
       "     sim-euclid   sim-dice  sim-jaccard  \n",
       "0     25.296228   0.808093          1.0  \n",
       "1     22.118834  -3.074252          1.0  \n",
       "2     14.640360 -24.627852          1.0  \n",
       "3     19.508880  -0.468402          1.0  \n",
       "4     12.063605   1.000000          1.0  \n",
       "..          ...        ...          ...  \n",
       "395   19.600983  -1.993741          1.0  \n",
       "396   18.980925  -3.418888          1.0  \n",
       "397   14.601425   1.000000          1.0  \n",
       "398   18.305506   5.200466          1.0  \n",
       "399   13.240623   9.162421          1.0  \n",
       "\n",
       "[400 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = [('cosine', cosine), ('dot', dot), ('euclid', euclid),\n",
    "                ('dice', dice), ('jaccard', jaccard)]\n",
    "for name, function in distances:\n",
    "    simpairs[f'sim-{name}'] = simpairs.apply(sim, axis=1, sim_f=function)\n",
    "simpairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning vocab: 100%|██████████| 77021/77021 [01:32<00:00, 828.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tượngđài', 0.9999999999999999), ('đềnthờ', 0.5623567247142175), ('thápchuông', 0.5443984164585618), ('biatưởngniệm', 0.5406205813189373), ('giáođường', 0.5329588054503885)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# task 2 with word: 'tượng_đài'. Note: words in vocabulary are all NORMALIZED! \n",
    "print(topn('tượng_đài', n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "42/42 [==============================] - 4s 13ms/step - loss: 0.6416 - binary_accuracy: 0.6183 - val_loss: 0.5367 - val_binary_accuracy: 0.7643\n",
      "Epoch 2/40\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.3276 - binary_accuracy: 0.8667 - val_loss: 0.5166 - val_binary_accuracy: 0.8286\n",
      "Epoch 3/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1143 - binary_accuracy: 0.9611 - val_loss: 0.5115 - val_binary_accuracy: 0.8786\n",
      "Epoch 4/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0502 - binary_accuracy: 0.9833 - val_loss: 0.5728 - val_binary_accuracy: 0.8714\n",
      "Epoch 5/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0360 - binary_accuracy: 0.9897 - val_loss: 0.6104 - val_binary_accuracy: 0.8714\n",
      "Epoch 6/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0177 - binary_accuracy: 0.9937 - val_loss: 0.7414 - val_binary_accuracy: 0.8571\n",
      "Epoch 7/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0144 - binary_accuracy: 0.9952 - val_loss: 0.6381 - val_binary_accuracy: 0.8786\n",
      "Epoch 8/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0151 - binary_accuracy: 0.9960 - val_loss: 0.6963 - val_binary_accuracy: 0.8643\n",
      "Epoch 9/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0120 - binary_accuracy: 0.9952 - val_loss: 0.6773 - val_binary_accuracy: 0.8786\n",
      "Epoch 10/40\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0114 - binary_accuracy: 0.9968 - val_loss: 0.9466 - val_binary_accuracy: 0.8429\n",
      "Epoch 11/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0131 - binary_accuracy: 0.9960 - val_loss: 0.7399 - val_binary_accuracy: 0.8714\n",
      "Epoch 12/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0107 - binary_accuracy: 0.9952 - val_loss: 0.7532 - val_binary_accuracy: 0.8714\n",
      "Epoch 13/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0099 - binary_accuracy: 0.9968 - val_loss: 0.7751 - val_binary_accuracy: 0.8714\n",
      "Epoch 14/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0094 - binary_accuracy: 0.9952 - val_loss: 0.7037 - val_binary_accuracy: 0.8857\n",
      "Epoch 15/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0137 - binary_accuracy: 0.9944 - val_loss: 0.7309 - val_binary_accuracy: 0.8714\n",
      "Epoch 16/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0103 - binary_accuracy: 0.9960 - val_loss: 0.7451 - val_binary_accuracy: 0.8714\n",
      "Epoch 17/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0110 - binary_accuracy: 0.9960 - val_loss: 0.8340 - val_binary_accuracy: 0.8500\n",
      "Epoch 18/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0108 - binary_accuracy: 0.9952 - val_loss: 0.7465 - val_binary_accuracy: 0.8714\n",
      "Epoch 19/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0088 - binary_accuracy: 0.9952 - val_loss: 0.6756 - val_binary_accuracy: 0.8857\n",
      "Epoch 20/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0140 - binary_accuracy: 0.9960 - val_loss: 0.6998 - val_binary_accuracy: 0.8714\n",
      "Epoch 21/40\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0096 - binary_accuracy: 0.9968 - val_loss: 0.7164 - val_binary_accuracy: 0.8714\n",
      "Epoch 22/40\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.0117 - binary_accuracy: 0.9952 - val_loss: 0.7411 - val_binary_accuracy: 0.8714\n",
      "Epoch 23/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0124 - binary_accuracy: 0.9944 - val_loss: 0.7372 - val_binary_accuracy: 0.8786\n",
      "Epoch 24/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0124 - binary_accuracy: 0.9944 - val_loss: 0.7519 - val_binary_accuracy: 0.8714\n",
      "Epoch 25/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0102 - binary_accuracy: 0.9968 - val_loss: 0.8231 - val_binary_accuracy: 0.8500\n",
      "Epoch 26/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0127 - binary_accuracy: 0.9944 - val_loss: 0.8163 - val_binary_accuracy: 0.8500\n",
      "Epoch 27/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0131 - binary_accuracy: 0.9960 - val_loss: 0.6538 - val_binary_accuracy: 0.8786\n",
      "Epoch 28/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0112 - binary_accuracy: 0.9968 - val_loss: 0.7525 - val_binary_accuracy: 0.8786\n",
      "Epoch 29/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0132 - binary_accuracy: 0.9944 - val_loss: 0.6163 - val_binary_accuracy: 0.8857\n",
      "Epoch 30/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0142 - binary_accuracy: 0.9952 - val_loss: 0.6778 - val_binary_accuracy: 0.8857\n",
      "Epoch 31/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0129 - binary_accuracy: 0.9952 - val_loss: 0.6050 - val_binary_accuracy: 0.8857\n",
      "Epoch 32/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0112 - binary_accuracy: 0.9960 - val_loss: 0.8640 - val_binary_accuracy: 0.8714\n",
      "Epoch 33/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0115 - binary_accuracy: 0.9937 - val_loss: 0.8008 - val_binary_accuracy: 0.8786\n",
      "Epoch 34/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0115 - binary_accuracy: 0.9944 - val_loss: 0.7807 - val_binary_accuracy: 0.8786\n",
      "Epoch 35/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0118 - binary_accuracy: 0.9952 - val_loss: 0.8245 - val_binary_accuracy: 0.8429\n",
      "Epoch 36/40\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.0109 - binary_accuracy: 0.9944 - val_loss: 0.6934 - val_binary_accuracy: 0.8786\n",
      "Epoch 37/40\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.0122 - binary_accuracy: 0.9968 - val_loss: 0.7149 - val_binary_accuracy: 0.8857\n",
      "Epoch 38/40\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0096 - binary_accuracy: 0.9952 - val_loss: 0.7797 - val_binary_accuracy: 0.8857\n",
      "Epoch 39/40\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0092 - binary_accuracy: 0.9968 - val_loss: 0.7490 - val_binary_accuracy: 0.8857\n",
      "Epoch 40/40\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0087 - binary_accuracy: 0.9968 - val_loss: 0.8777 - val_binary_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a197010a90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! pip install tensorboard\n",
    "# ! pip install tensorflow\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=X.shape[1:]),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "  ])\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          batch_size=30,\n",
    "          epochs=40, \n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 0s/step - loss: 0.8777 - binary_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8776617050170898, 0.8571428656578064]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    x=x_test,\n",
    "    y=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.4943371e-04 9.9905056e-01]]\n",
      "SYN\n"
     ]
    }
   ],
   "source": [
    "def predict(w1:str, w2:str)->str:\n",
    "    w1 = word2vec(word2norm(w1))\n",
    "    w2 = word2vec(word2norm(w2))\n",
    "    input = np.array([[w1,w2]])\n",
    "    output = model.predict(input)\n",
    "    print(output)\n",
    "    return enc.inverse_transform(output)[0][0]\n",
    "\n",
    "print(predict('thanh_danh','ô_nhục'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9ab610a55a5176458df2dff96f548f03c9f71ac1d536db2e7e5f1815100f41c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
